{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: Vi\n",
    "# Created on: 2024-06-26 09:17:19\n",
    "# Description: Experiments for tuning and optimizing the model\n",
    "import os\n",
    "import wandb\n",
    "import datetime\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import utils.wlog as wlog\n",
    "from utils.common import clear_jupyter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"), relogin=True) # 登录wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Configuration\n",
    "from argparse import Namespace\n",
    "\n",
    "feature_config = Namespace(\n",
    "    type=\"MEL_SPECTROGRAM\",\n",
    "    args=Namespace(\n",
    "        sample_rate=32000,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        win_length=None\n",
    "        # ⭐ n_mels in sweep_config\n",
    "    ).__dict__\n",
    ")\n",
    "\n",
    "CONFIG = Namespace(\n",
    "    project_name=\"Noise-Model-S-Sweep-Test\",\n",
    "    seed=1202,\n",
    "    model_type=\"CNN10\",\n",
    "    feature = feature_config.__dict__,\n",
    "    duration=10,\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    # # ⭐ 需要扫描的参数写在sweep_config的parameters_dict里面\n",
    "    # optimizer=\"adam\",\n",
    "    # n_mels=64,\n",
    "    # dropout=0.1,\n",
    "    # lr=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Configuration: https://docs.wandb.ai/guides/sweeps/define-sweep-configuration\n",
    "sweep_count = 5 # 定义搜索次数\n",
    "\n",
    "sweep_config = {\"method\": \"random\"}  # grid, random, bayes\n",
    "\n",
    "metric = {\n",
    "    \"name\": \"accuracy\",\n",
    "    \"goal\": \"maximize\",  # minimize\n",
    "}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"values\": [\"adam\", \"sgd\"]},\n",
    "    \"n_mels\": {\"values\": list(range(64, 257, 32))},\n",
    "    \"dropout\": {\"distribution\": \"uniform\", \"min\": 0, \"max\": 0.6},\n",
    "    \"lr\": {\n",
    "        \"distribution\": \"uniform\",  # log_uniform_values, uniform, q_uniform\n",
    "        \"min\": 1e-6,\n",
    "        \"max\": 0.1,\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "# 定义剪枝策略, 提前终止那些没有希望的任务\n",
    "sweep_config['early_terminate'] = {\n",
    "    'type':'hyperband',\n",
    "    'min_iter':3,\n",
    "    'eta':2,\n",
    "    's':3\n",
    "} #在step=3, 6, 12 时考虑是否剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建sweep\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep_config, \n",
    "    project=CONFIG.project_name\n",
    ") # ⭐如果需要继续之前的sweep，在网页上找到对应的sweep id，直接赋值即可 sweep_id = \"xxxxxx\" \n",
    "\n",
    "sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⭐ Customized for the Dataset\n",
    "import datasets.SupportedSources as Sources\n",
    "from datasets.SupportedSources import SupportedSourceTypes as SST\n",
    "from datasets import Label, Category, DatasetFactory\n",
    "\n",
    "from utils.audio.features import get_feature_transformer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_labels():# ⭐修改数据标签\n",
    "    # nature = Sources.get_data_source(SST.NATURE)\n",
    "    # traffic = Sources.get_data_source(SST.TRAFFIC)\n",
    "\n",
    "    # labels = nature.get_childs(\"雷声,蛙声,蝉鸣声,狗叫声\".split(',')) + traffic.childs\n",
    "\n",
    "    # bird_label = Label(\n",
    "    #     name='鸟叫',\n",
    "    #     sources=nature.get_childs(\n",
    "    #         # ['北红尾鸲叫声', '叉尾太阳鸟叫声', '大鹰鹃叫声', '强脚树莺叫声', '普通夜鹰叫声', '棕颈钩嘴鹛叫声', '淡脚柳莺叫声']\n",
    "    #         ['长尾缝叶莺叫声', '普通夜鹰叫声', '大鹰鹃叫声']\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # labels.append(bird_label)\n",
    "    \n",
    "    nature = Sources.get_data_source(SST.NATURE)\n",
    "    labels = nature.childs[:2] # 测试用，只取两个标签\n",
    "    return labels\n",
    "\n",
    "def get_category(name:str):\n",
    "    labels = get_labels()\n",
    "    category = Category(name=name, labels=labels)\n",
    "    return category\n",
    "\n",
    "def get_extractor(feature_type:str, feature_args:dict,**kwargs):\n",
    "    extractor = get_feature_transformer(feature_type, **feature_args, **kwargs)\n",
    "    return extractor\n",
    "    \n",
    "def get_dataset(category, target_sr, duration, feature_type, feature_args, **kwargs):\n",
    "    factory = DatasetFactory(category, test_ratio=0.2, seed=CONFIG.seed)\n",
    "    extractor = get_extractor(feature_type, feature_args, **kwargs) # ⭐ 注意这里的kwargs参数，根据实际情况传入\n",
    "    train_dataset = factory.create_dataset(train=True, target_sr=target_sr,duration=duration,extractor=extractor)\n",
    "    test_dataset = factory.create_dataset(train=False, target_sr=target_sr,duration=duration,extractor=extractor)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def get_dataloader(train_dataset, test_dataset):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True, num_workers=CONFIG.num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG.batch_size, shuffle=False, num_workers=CONFIG.num_workers)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 定义函数，用于获取测试集的音频文件名和标签名称，用于在测试时记录预测错误的结果\n",
    "def get_file_path(index, test_dataset):\n",
    "    return os.path.basename(test_dataset._get_audio_path(index))\n",
    "\n",
    "def get_label_name(index, category):\n",
    "    return category.get_label(index).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def get_num_class(category:Category):\n",
    "    return len(category.labels)\n",
    "\n",
    "def get_model_input_size(dataset):\n",
    "    input_size = dataset[0][0].shape[2]\n",
    "    return input_size\n",
    "\n",
    "def get_model(**kwargs):\n",
    "    if CONFIG.model_type == 'CNN10':\n",
    "        from models.panns import CNN10 as Model # args: num_class, input_size, dropout\n",
    "        # ⭐️ Add your custom model here ⭐️\n",
    "    else:\n",
    "        raise ValueError('Invalid model type: {}'.format(CONFIG.model_type))\n",
    "    model = Model(**kwargs).to(DEVICE)\n",
    "    print(repr(model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "def get_optimizer(type_, model, lr):\n",
    "    if type_ == 'adam':\n",
    "        return Adam(model.parameters(), lr=lr)\n",
    "    elif type_ =='sgd':\n",
    "        return SGD(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError('Invalid optimizer type')\n",
    "    \n",
    "def get_lr_scheduler(optimizer, type_='exp', step_size=10, gamma=0.1):\n",
    "    if type_ == 'exp':\n",
    "        return torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    else:\n",
    "        raise ValueError('Invalid lr scheduler type')\n",
    "    \n",
    "# Loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def get_loss_fn(type_='crossentropy'):\n",
    "    if type_ == 'crossentropy':\n",
    "        return CrossEntropyLoss()\n",
    "    else:\n",
    "        raise ValueError('Invalid loss function type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep agent for hyperparameter tuning and optimization\n",
    "from utils.pytorch import Trainer, Tester\n",
    "\n",
    "def train(config):\n",
    "    save_dir = os.path.join('training', datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    category = get_category(name=\"test\")\n",
    "\n",
    "    wandb.log({\"Label\": wlog.df2table(category.labels_dataframe)})\n",
    "    \n",
    "    train_dataset, test_dataset = get_dataset(\n",
    "        category,\n",
    "        target_sr=config.feature.get('args').get('sample_rate'),\n",
    "        duration=config.duration,\n",
    "        feature_type=config.feature.get('type'),\n",
    "        feature_args=config.feature.get('args'),\n",
    "        n_mels=config.n_mels,  # ⭐ sweep n_mels\n",
    "    )  # ⭐ 注意这里的kwargs参数，根据实际情况传入，例如这里的n_mels\n",
    "    \n",
    "    train_dataloader, test_dataloader = get_dataloader(train_dataset, test_dataset)\n",
    "    \n",
    "    num_class = get_num_class(category)\n",
    "    input_size = get_model_input_size(train_dataset)\n",
    "    model = get_model(\n",
    "        num_class=num_class, \n",
    "        input_size=input_size, \n",
    "        dropout=config.dropout # ⭐ sweep dropout\n",
    "    )\n",
    "    \n",
    "    optimizer = get_optimizer(\n",
    "        type_=config.optimizer, # ⭐ sweep optimizer\n",
    "        model=model, \n",
    "        lr=config.lr # ⭐ sweep lr\n",
    "    )\n",
    "    lr_scheduler = get_lr_scheduler(optimizer=optimizer)\n",
    "    loss_fn = get_loss_fn()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        training_dataloader=train_dataloader,\n",
    "        loss_func=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=lr_scheduler,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    best_acc = 0.0 # 最佳准确率\n",
    "    tqdm_instance = tqdm(range(config.epochs))\n",
    "    for i in tqdm_instance:\n",
    "        train_loss = trainer.train_an_epoch(tqdm_instance=tqdm_instance)\n",
    "        tester = Tester.from_trainer(\n",
    "            trainer,\n",
    "            test_dataloader,\n",
    "            num_class,\n",
    "        )\n",
    "        metrics, bad_cases = tester.test_an_epoch(\n",
    "            get_file_path=partial(get_file_path, test_dataset=test_dataset),\n",
    "            get_label_name=partial(get_label_name, category=category),\n",
    "            tqdm_instance=tqdm_instance,\n",
    "        )\n",
    "        if metrics.accuracy > best_acc:\n",
    "            best_acc = metrics.accuracy\n",
    "            trainer.save_model(os.path.join(save_dir, \"best_model.pth\"))\n",
    "            trainer.save_optimizer(os.path.join(save_dir, \"optimizer.pth\"))\n",
    "            with open(os.path.join(save_dir, 'best_acc.txt'), 'w') as f:\n",
    "                f.write(f'[{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}] model:{repr(model)}, Epoch: {i+1}, Best Accuracy: {best_acc:.4f}, Optimizer: {type(optimizer).__name__}')\n",
    "        log_info = {\"Epoch\": i + 1, \"train_loss\": train_loss, 'lr':optimizer.param_groups[0]['lr']}\n",
    "        if weight_decay:=optimizer.param_groups[0].get('weight_decay', None) is not None:\n",
    "            log_info['weight_decay'] = weight_decay\n",
    "        for key, value in metrics.model_dump().items():\n",
    "            if value is not None:\n",
    "                log_info[key] = value\n",
    "        wandb.log(log_info)\n",
    "        wandb.log({\"bad_cases\": wlog.df2table(bad_cases)})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⭐start\n",
    "def main():\n",
    "    wandb.init(\n",
    "        project=CONFIG.project_name,\n",
    "        name=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        config=CONFIG.__dict__,\n",
    "        save_code=True,\n",
    "    )\n",
    "    train(wandb.config)\n",
    "    \n",
    "wandb.agent(sweep_id=sweep_id, function=main, count=sweep_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
