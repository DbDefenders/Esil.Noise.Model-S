{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "'''\n",
    "@Time    :   2024/06/14 14:17:48\n",
    "@Author  :   Fenrir \n",
    "@Contact :   746055404@qq.com\n",
    "@Description :   测试训练\n",
    "'''\n",
    "import wandb\n",
    "import random\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "load_dotenv()\n",
    "WANDB_API_KEY = os.getenv('WANDB_API_KEY')\n",
    "from utils import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wandb 启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(WANDB_API_KEY)\n",
    "# # start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"LKJ-test-training\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"architecture\": \"My_CNN_10\",\n",
    "        \"dataset\": \"省数据库\",\n",
    "        \"epochs\": 5,\n",
    "    },\n",
    "    name=datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化config类，并加载配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureParams = config.features\n",
    "TrainsParams = config.train\n",
    "DataSources = config.data_sources\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device,torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***构建特征提取器***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "# extractor = torchaudio.transforms.MelSpectrogram(sample_rate=FeatureParams['MEL_SPECTROGRAM']['sample_rate'], hop_length=FeatureParams['MEL_SPECTROGRAM']['hop_length'],\n",
    "#                                                  n_fft=FeatureParams['MEL_SPECTROGRAM']['n_fft'],n_mels=FeatureParams['MEL_SPECTROGRAM']['n_mels'],f_min=FeatureParams['MEL_SPECTROGRAM']['fmin'],\n",
    "#                                                  f_max=FeatureParams['MEL_SPECTROGRAM']['fmax'],mel_scale='slaney',center=True, pad_mode='reflect')\n",
    "# 加载特征提取器\n",
    "from utils.audio.extractor import Extractor, FeatureType\n",
    "\n",
    "features = [\n",
    "    FeatureType.SPECTROGRAM,\n",
    "    FeatureType.MEL_SPECTROGRAM,\n",
    "    FeatureType.MFCC   \n",
    "]\n",
    "\n",
    "extractor = Extractor(sample_rate=44100, features=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***自由选取训练数据集，这里选用自然+交通数据集，其中鸟类数据集为混合数据集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import DatasetFactory, Category, Label\n",
    "from datasets.SupportedSources import NATURE, TRAFFIC, ESC50\n",
    "labels = [\n",
    "    NATURE.get_child(\"雷声\"),\n",
    "    NATURE.get_child(\"蛙声\"),\n",
    "    NATURE.get_child(\"蝉鸣声\"),\n",
    "    NATURE.get_child(\"狗叫声\"),\n",
    "    Label(\n",
    "        name='鸟叫',\n",
    "        sources=NATURE.get_childs(\n",
    "            ['北红尾鸲叫声', '叉尾太阳鸟叫声', '大鹰鹃叫声', '强脚树莺叫声', '普通夜鹰叫声', '棕颈钩嘴鹛叫声', '淡脚柳莺叫声']\n",
    "        )\n",
    "    )\n",
    "] + TRAFFIC.childs\n",
    "# labels = [\n",
    "#     NATURE.get_child(\"雷声\"),\n",
    "#     NATURE.get_child(\"蛙声\"),\n",
    "#     NATURE.get_child(\"蝉鸣声\"),\n",
    "#     NATURE.get_child(\"狗叫声\"),\n",
    "#     Label(\n",
    "#         name='鸟叫',\n",
    "#         sources=NATURE.get_childs(\n",
    "#             ['北红尾鸲叫声', '叉尾太阳鸟叫声', '大鹰鹃叫声', '强脚树莺叫声', '普通夜鹰叫声', '棕颈钩嘴鹛叫声', '淡脚柳莺叫声']\n",
    "#         ) + ESC50.get_childs('chirping_birds')\n",
    "#     )\n",
    "# ] + TRAFFIC.childs\n",
    "\n",
    "\n",
    "category = Category(name=\"自然+交通\", labels=labels)\n",
    "LABELS = [item['name'] for item in category.labels_info]\n",
    "len(labels),len(category) # 类别25类, 标签数（11+20）*1200+40=37240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***使用datasetfactory把选择的数据集进行处理排序得到全新排序的数据集，并随机分成训练集和测试集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = DatasetFactory(category=category, test_ratio=0.2, seed=1202)\n",
    "# dataset_factory.count_train_test_data()\n",
    "# dataset_factory.category.get_label(index=22), dataset_factory.category.get_label(index=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***生成训练数据集、测试数据集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset_factory.create_dataset(train=True, target_sr=32000, duration=10, extractor=extractor)\n",
    "test_data = dataset_factory.create_dataset(train=False, target_sr=32000, duration=10, extractor=extractor)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***创建dataloader***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_data, batch_size=TrainsParams['batch_size'], shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=TrainsParams['batch_size'],  shuffle=False)\n",
    "len(train_dataloader), len(test_dataloader),TrainsParams['batch_size']\n",
    "\n",
    "\n",
    "'''测试少量数据集'''\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data.dataset import random_split\n",
    "\n",
    "# # 计算要使用的训练数据集的大小\n",
    "# train_size = int(len(train_data) * 0.1)\n",
    "\n",
    "# # 使用 random_split 将数据集分为两部分，只取前百分之十\n",
    "# train_data_subset, _ = random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "\n",
    "# # 创建只包含百分之十数据的 DataLoader\n",
    "# train_dataloader_subset = DataLoader(train_data_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "# # 对于测试数据集，您也可以做类似的处理\n",
    "# test_size = int(len(test_data) * 0.1)\n",
    "# test_data_subset, _ = random_split(test_data, [test_size, len(test_data) - test_size])\n",
    "# test_dataloader_subset = DataLoader(test_data_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "# # 输出 DataLoader 的大小和 batch_size\n",
    "# len(train_dataloader_subset), len(test_dataloader_subset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***创建模型***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***初始化***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pytorch as pt\n",
    "from models import MyCNN10\n",
    "\n",
    "# INPUT_HEIGHT = 431\n",
    "INPUT_HEIGHT = 313\n",
    "model = MyCNN10(num_classes=len(LABELS), input_height=INPUT_HEIGHT).to(device)\n",
    "optimizer, scheduler, scaler, loss_func = pt.initialization(train_dataloader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***测试model形状***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,512,626))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''测试特征提取完的shape'''\n",
    "# from tqdm.notebook import tqdm\n",
    "# n = 0\n",
    "# for idx, (features, label) in enumerate(tqdm(train_dataloader_subset,leave=False ,desc=\"[train]\")):  # 遍历数据加载器，使用tqdm显示进度条\n",
    "#     # label = label.reshape(-1, len(LABELS))  # 用于调整标签的形状\n",
    "#     n += 1\n",
    "#     features, label = features.to(device), label.to(device)\n",
    "#     print(features.shape, label.shape)\n",
    "#     model(features)  # 模型前向传播\n",
    "#     # if n > 10:\n",
    "#     #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:    \n",
    "    time_point = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    save_dir_base = f\"experiments/training/{TrainsParams['model_name']}-{time_point}\"\n",
    "    save_dir = f\"{save_dir_base}/models\"\n",
    "\n",
    "    latest_dir = f\"{save_dir_base}/latest\"\n",
    "    latest_model_path = f\"{latest_dir}/model.pth\"\n",
    "    latest_optimizer_path = f\"{latest_dir}/optimizer.pth\"\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not os.path.exists(latest_dir):\n",
    "        os.makedirs(latest_dir)\n",
    "    print(f\"Save directory: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import timeit\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm_ = tqdm(range(TrainsParams['start_epoch'], TrainsParams['max_epochs']))\n",
    "print(device)\n",
    "# n = 0\n",
    "best_f1 = TrainsParams['best_f1']\n",
    "best_auc = TrainsParams['best_auc']\n",
    "best_loss = TrainsParams['best_loss']\n",
    "for epoch in tqdm_:\n",
    "    print(epoch)\n",
    "    # start_time = time.time()\n",
    "    # 训练\n",
    "    model, optimizer, scaler, scheduler, trainloss = pt.train_an_epoch(model=model, optimizer=optimizer, \n",
    "                                                                     training_dataloader=train_dataloader, \n",
    "                                                                     scheduler=scheduler,scaler=scaler, loss_func=loss_func,tag_wandb=False)\n",
    "    # 测试\n",
    "    validloss, auc, prec, rec, acc, f1, f1_micro = pt.test_an_epoch(model=model, testing_dataloader=test_dataloader, loss_func=loss_func, LABELS=LABELS,tag_wandb=False)\n",
    "    # n += 1\n",
    "    # if n > 1:\n",
    "    #     break\n",
    "    if TrainsParams['best_loss'] < validloss:\n",
    "        best_model = model\n",
    "        best_f1 = f1\n",
    "        best_auc = auc\n",
    "        best_loss = validloss\n",
    "        # end_time = time.time()\n",
    "    pt.save_model(best_model.state_dict(), TrainsParams['best_model_path'])\n",
    "    print(f\"best model saved\")\n",
    "    print(f\"单次训练耗时：{timeit.timeit(pt.train_an_epoch, number=1):.2f}\")\n",
    "    print(f\"单次测试耗时：{timeit.timeit(pt.test_an_epoch, number=1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if True:\n",
    "    wandb.log({f\"best_loss\": best_loss,\n",
    "                f\"best_f1\": best_f1,\n",
    "                f\"best_auc\":best_auc})\n",
    "# del model, best_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"--\")\n",
    "wandb.finish()\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lkj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
